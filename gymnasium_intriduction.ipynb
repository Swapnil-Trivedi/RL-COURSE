{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4ba513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dff83c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== classic_control =====\n",
      "Acrobot-v1             CartPole-v0            CartPole-v1\n",
      "MountainCar-v0         MountainCarContinuous-v0 Pendulum-v1\n",
      "===== phys2d =====\n",
      "phys2d/CartPole-v0     phys2d/CartPole-v1     phys2d/Pendulum-v0\n",
      "===== box2d =====\n",
      "BipedalWalker-v3       BipedalWalkerHardcore-v3 CarRacing-v3\n",
      "LunarLander-v3         LunarLanderContinuous-v3\n",
      "===== toy_text =====\n",
      "Blackjack-v1           CliffWalking-v1        CliffWalkingSlippery-v1\n",
      "FrozenLake-v1          FrozenLake8x8-v1       Taxi-v3\n",
      "===== tabular =====\n",
      "tabular/Blackjack-v0   tabular/CliffWalking-v0\n",
      "===== None =====\n",
      "Ant-v2                 Ant-v3                 GymV21Environment-v0\n",
      "GymV26Environment-v0   HalfCheetah-v2         HalfCheetah-v3\n",
      "Hopper-v2              Hopper-v3              Humanoid-v2\n",
      "Humanoid-v3            HumanoidStandup-v2     InvertedDoublePendulum-v2\n",
      "InvertedPendulum-v2    Pusher-v2              Reacher-v2\n",
      "Swimmer-v2             Swimmer-v3             Walker2d-v2\n",
      "Walker2d-v3\n",
      "===== mujoco =====\n",
      "Ant-v4                 Ant-v5                 HalfCheetah-v4\n",
      "HalfCheetah-v5         Hopper-v4              Hopper-v5\n",
      "Humanoid-v4            Humanoid-v5            HumanoidStandup-v4\n",
      "HumanoidStandup-v5     InvertedDoublePendulum-v4 InvertedDoublePendulum-v5\n",
      "InvertedPendulum-v4    InvertedPendulum-v5    Pusher-v4\n",
      "Pusher-v5              Reacher-v4             Reacher-v5\n",
      "Swimmer-v4             Swimmer-v5             Walker2d-v4\n",
      "Walker2d-v5\n"
     ]
    }
   ],
   "source": [
    "# Get list of all available environments\n",
    "gym.pprint_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282697e2",
   "metadata": {},
   "source": [
    "## CartPole-V1 Environment using Gymnasium\n",
    "link : https://gymnasium.farama.org/environments/classic_control/cart_pole/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c8e4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting observation: [-0.04908921 -0.03809413  0.04986965 -0.0231809 ]\n",
      "Episode finished! Total reward: 23.0\n"
     ]
    }
   ],
   "source": [
    "# Run `pip install \"gymnasium[classic-control]\"` for this example.\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create our training environment - a cart with a pole that needs balancing\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Reset environment to start a new episode\n",
    "observation, info = env.reset()\n",
    "# observation: what the agent can \"see\" - cart position, velocity, pole angle, etc.\n",
    "# info: extra debugging information (usually not needed for basic learning)\n",
    "\n",
    "print(f\"Starting observation: {observation}\")\n",
    "# Example output: [ 0.01234567 -0.00987654  0.02345678  0.01456789]\n",
    "# [cart_position, cart_velocity, pole_angle, pole_angular_velocity]\n",
    "\n",
    "episode_over = False\n",
    "total_reward = 0\n",
    "\n",
    "while not episode_over:\n",
    "    # Choose an action: 0 = push cart left, 1 = push cart right\n",
    "    action = env.action_space.sample()  # Random action for now - real agents will be smarter!\n",
    "\n",
    "    # Take the action and see what happens\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "    \n",
    "\n",
    "print(f\"Episode finished! Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903c2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-COURSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
